{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "87965c894d3b7f3b3dfc66d8c2a60efcc08a370d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>emotion</td>\n",
       "      <td>pixels</td>\n",
       "      <td>Usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     usage\n",
       "0  emotion                                             pixels     Usage\n",
       "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
       "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
       "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
       "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
       "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data\n",
    "filname = 'F:/fer2013.csv'\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "names=['emotion','pixels','usage']\n",
    "df=pd.read_csv('F:/fer2013.csv',names=names, na_filter=False)\n",
    "im=df['pixels']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "bfde4d91ff367dfa6764202c1b309ea291fb833a"
   },
   "outputs": [],
   "source": [
    "def getData(filname):\n",
    "    # images are 48x48\n",
    "    # N = 35887\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True\n",
    "    for line in open(filname):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "435d0e06553e3de3fd982e4a4a86c28018ac3913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "X, Y = getData(filname)\n",
    "num_class = len(set(Y))\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the image and the respective expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[7].reshape(48,48))\n",
    "print(label_map[Y[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f3c6bfb7aaf3c25ba7cdd5621e4d62b9eaa5502e"
   },
   "outputs": [],
   "source": [
    "\n",
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)\n",
    "y_train=(np.arange(num_class)==y_train[:,None]).astype(np.float32)\n",
    "y_test=(np.arange(num_class)==y_test[:,None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 46, 46, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 166,791\n",
      "Trainable params: 166,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),input_shape=(48,48,1),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(7,activation='softmax')\n",
    "    \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 17s 583us/sample - loss: 1.7835 - acc: 0.2634 - val_loss: 1.7006 - val_acc: 0.3342\n",
      "Epoch 2/20\n",
      "28709/28709 [==============================] - 16s 558us/sample - loss: 1.5465 - acc: 0.3947 - val_loss: 1.4643 - val_acc: 0.43160.3 - ETA\n",
      "Epoch 3/20\n",
      "28709/28709 [==============================] - 15s 528us/sample - loss: 1.4022 - acc: 0.4601 - val_loss: 1.4176 - val_acc: 0.4574\n",
      "Epoch 4/20\n",
      "28709/28709 [==============================] - 14s 492us/sample - loss: 1.3168 - acc: 0.4937 - val_loss: 1.3244 - val_acc: 0.4997\n",
      "Epoch 5/20\n",
      "28709/28709 [==============================] - 16s 543us/sample - loss: 1.2571 - acc: 0.5204 - val_loss: 1.2763 - val_acc: 0.5124\n",
      "Epoch 6/20\n",
      "28709/28709 [==============================] - 16s 542us/sample - loss: 1.2131 - acc: 0.5385 - val_loss: 1.2475 - val_acc: 0.5298\n",
      "Epoch 7/20\n",
      "28709/28709 [==============================] - 16s 566us/sample - loss: 1.1726 - acc: 0.5526 - val_loss: 1.2251 - val_acc: 0.5391\n",
      "Epoch 8/20\n",
      "28709/28709 [==============================] - 16s 566us/sample - loss: 1.1425 - acc: 0.5672 - val_loss: 1.2181 - val_acc: 0.5337\n",
      "Epoch 9/20\n",
      "28709/28709 [==============================] - 16s 565us/sample - loss: 1.1180 - acc: 0.5772 - val_loss: 1.1913 - val_acc: 0.5525\n",
      "Epoch 10/20\n",
      "28709/28709 [==============================] - 16s 565us/sample - loss: 1.0906 - acc: 0.5860 - val_loss: 1.1889 - val_acc: 0.5433\n",
      "Epoch 11/20\n",
      "28709/28709 [==============================] - 16s 570us/sample - loss: 1.0671 - acc: 0.5952 - val_loss: 1.1862 - val_acc: 0.5451\n",
      "Epoch 12/20\n",
      "28709/28709 [==============================] - 15s 506us/sample - loss: 1.0453 - acc: 0.6045 - val_loss: 1.1806 - val_acc: 0.5566\n",
      "Epoch 13/20\n",
      "28709/28709 [==============================] - 15s 507us/sample - loss: 1.0208 - acc: 0.6149 - val_loss: 1.1659 - val_acc: 0.5638\n",
      "Epoch 14/20\n",
      "28709/28709 [==============================] - 16s 562us/sample - loss: 1.0079 - acc: 0.6187 - val_loss: 1.1546 - val_acc: 0.5645\n",
      "Epoch 15/20\n",
      "28709/28709 [==============================] - 16s 564us/sample - loss: 0.9863 - acc: 0.6309 - val_loss: 1.1518 - val_acc: 0.5631\n",
      "Epoch 16/20\n",
      "28709/28709 [==============================] - 16s 563us/sample - loss: 0.9688 - acc: 0.6366 - val_loss: 1.1628 - val_acc: 0.5610\n",
      "Epoch 17/20\n",
      "28709/28709 [==============================] - 16s 563us/sample - loss: 0.9432 - acc: 0.6459 - val_loss: 1.1490 - val_acc: 0.5692\n",
      "Epoch 18/20\n",
      "28709/28709 [==============================] - 16s 562us/sample - loss: 0.9331 - acc: 0.6501 - val_loss: 1.1404 - val_acc: 0.5750\n",
      "Epoch 19/20\n",
      "28709/28709 [==============================] - 16s 563us/sample - loss: 0.9035 - acc: 0.6606 - val_loss: 1.1854 - val_acc: 0.5549\n",
      "Epoch 20/20\n",
      "28709/28709 [==============================] - 16s 556us/sample - loss: 0.8912 - acc: 0.6676 - val_loss: 1.1500 - val_acc: 0.5683\n"
     ]
    }
   ],
   "source": [
    "path_model='F:/fer_model_checkpoint/model_filter.h5'\n",
    "history=model.fit(x=X_train,\n",
    "                 y=y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs=20,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_test,y_test),\n",
    "                 callbacks=[(ModelCheckpoint(filepath=path_model))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have achieved top three validation score of 57.50%, 56.92% and 56.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Dropout layer to the existing model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 46, 46, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 166,791\n",
      "Trainable params: 166,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),input_shape=(48,48,1),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(7,activation='softmax')\n",
    "    \n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the image augmentation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-fabc7bfd7f5a>:12: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 225 steps, validate on 7178 samples\n",
      "Epoch 1/30\n",
      "225/225 [==============================] - 17s 77ms/step - loss: 1.7665 - acc: 0.2689 - val_loss: 1.8130 - val_acc: 0.2488\n",
      "Epoch 2/30\n",
      "225/225 [==============================] - 17s 76ms/step - loss: 1.6266 - acc: 0.3489 - val_loss: 1.7365 - val_acc: 0.3072\n",
      "Epoch 3/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.5062 - acc: 0.4097 - val_loss: 1.6991 - val_acc: 0.3472\n",
      "Epoch 4/30\n",
      "225/225 [==============================] - 21s 95ms/step - loss: 1.4356 - acc: 0.4459 - val_loss: 1.6442 - val_acc: 0.3579\n",
      "Epoch 5/30\n",
      "225/225 [==============================] - 23s 101ms/step - loss: 1.3928 - acc: 0.4592 - val_loss: 1.6083 - val_acc: 0.3713\n",
      "Epoch 6/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.3563 - acc: 0.4783 - val_loss: 1.5620 - val_acc: 0.3794\n",
      "Epoch 7/30\n",
      "225/225 [==============================] - 21s 95ms/step - loss: 1.3347 - acc: 0.4859 - val_loss: 1.5587 - val_acc: 0.3654\n",
      "Epoch 8/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.3145 - acc: 0.4957 - val_loss: 1.5666 - val_acc: 0.3647\n",
      "Epoch 9/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.2848 - acc: 0.5055 - val_loss: 1.4875 - val_acc: 0.4260\n",
      "Epoch 10/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.2805 - acc: 0.5057 - val_loss: 1.4940 - val_acc: 0.4505\n",
      "Epoch 11/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.2619 - acc: 0.5175 - val_loss: 1.4685 - val_acc: 0.4295\n",
      "Epoch 12/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.2546 - acc: 0.5210 - val_loss: 1.4528 - val_acc: 0.4426\n",
      "Epoch 13/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.2456 - acc: 0.5229 - val_loss: 1.5018 - val_acc: 0.3983\n",
      "Epoch 14/30\n",
      "225/225 [==============================] - 23s 102ms/step - loss: 1.2302 - acc: 0.5286 - val_loss: 1.4754 - val_acc: 0.4207\n",
      "Epoch 15/30\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 1.2274 - acc: 0.5302 - val_loss: 1.6001 - val_acc: 0.3433\n",
      "Epoch 16/30\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 1.2134 - acc: 0.5401 - val_loss: 1.4398 - val_acc: 0.4301\n",
      "Epoch 17/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.2122 - acc: 0.5350 - val_loss: 1.4685 - val_acc: 0.4192\n",
      "Epoch 18/30\n",
      "225/225 [==============================] - 22s 100ms/step - loss: 1.2012 - acc: 0.5438 - val_loss: 1.4368 - val_acc: 0.4589\n",
      "Epoch 19/30\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 1.1913 - acc: 0.5457 - val_loss: 1.4550 - val_acc: 0.4482\n",
      "Epoch 20/30\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 1.1910 - acc: 0.5462 - val_loss: 1.4556 - val_acc: 0.4553\n",
      "Epoch 21/30\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 1.1854 - acc: 0.5458 - val_loss: 1.4005 - val_acc: 0.4638\n",
      "Epoch 22/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.1703 - acc: 0.5568 - val_loss: 1.4219 - val_acc: 0.4420\n",
      "Epoch 23/30\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 1.1784 - acc: 0.5505 - val_loss: 1.5333 - val_acc: 0.3938\n",
      "Epoch 24/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.1695 - acc: 0.5545 - val_loss: 1.4449 - val_acc: 0.4434\n",
      "Epoch 25/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.1583 - acc: 0.5572 - val_loss: 1.4041 - val_acc: 0.4620\n",
      "Epoch 26/30\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 1.1582 - acc: 0.5584 - val_loss: 1.4050 - val_acc: 0.4628\n",
      "Epoch 27/30\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 1.1497 - acc: 0.5609 - val_loss: 1.4812 - val_acc: 0.4324\n",
      "Epoch 28/30\n",
      "225/225 [==============================] - 23s 104ms/step - loss: 1.1449 - acc: 0.5637 - val_loss: 1.4875 - val_acc: 0.4136\n",
      "Epoch 29/30\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 1.1453 - acc: 0.5659 - val_loss: 1.3572 - val_acc: 0.4777\n",
      "Epoch 30/30\n",
      "225/225 [==============================] - 19s 84ms/step - loss: 1.1399 - acc: 0.5631 - val_loss: 1.4188 - val_acc: 0.4493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x196109e61c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "datagen.fit(X_train)\n",
    "path_model='model_filter.h5'\n",
    "model.fit_generator(datagen.flow(X_train,y_train,batch_size=128),\n",
    "                   epochs=30,validation_data=(X_test,y_test),\n",
    "                 callbacks=[(ModelCheckpoint(filepath=path_model))],verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With image augmentation technique we have got top three validation score of, 47.77%, 46.28%,45.89%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_79 (Conv2D)           (None, 46, 46, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 695,687\n",
      "Trainable params: 695,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Adding two Dropout layers to the existing CNN model\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),input_shape=(48,48,1),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1024,activation='relu'),\n",
    "    tf.keras.layers.Dense(7,activation='softmax')\n",
    "    \n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 7178 samples\n",
      "Epoch 1/30\n",
      "28709/28709 [==============================] - 18s 624us/sample - loss: 1.7741 - acc: 0.2740 - val_loss: 1.6139 - val_acc: 0.3695\n",
      "Epoch 2/30\n",
      "28709/28709 [==============================] - 17s 577us/sample - loss: 1.5385 - acc: 0.3976 - val_loss: 1.4402 - val_acc: 0.4384\n",
      "Epoch 3/30\n",
      "28709/28709 [==============================] - 16s 571us/sample - loss: 1.4130 - acc: 0.4553 - val_loss: 1.3565 - val_acc: 0.4791\n",
      "Epoch 4/30\n",
      "28709/28709 [==============================] - 16s 570us/sample - loss: 1.3269 - acc: 0.4883 - val_loss: 1.3093 - val_acc: 0.4879\n",
      "Epoch 5/30\n",
      "28709/28709 [==============================] - 16s 575us/sample - loss: 1.2695 - acc: 0.5130 - val_loss: 1.2525 - val_acc: 0.5199\n",
      "Epoch 6/30\n",
      "28709/28709 [==============================] - 16s 568us/sample - loss: 1.2189 - acc: 0.5359 - val_loss: 1.2786 - val_acc: 0.5074\n",
      "Epoch 7/30\n",
      "28709/28709 [==============================] - 16s 573us/sample - loss: 1.1835 - acc: 0.5464 - val_loss: 1.2321 - val_acc: 0.5222\n",
      "Epoch 8/30\n",
      "28709/28709 [==============================] - 16s 572us/sample - loss: 1.1429 - acc: 0.5610 - val_loss: 1.1986 - val_acc: 0.5425\n",
      "Epoch 9/30\n",
      "28709/28709 [==============================] - 17s 578us/sample - loss: 1.1158 - acc: 0.5761 - val_loss: 1.1723 - val_acc: 0.5469\n",
      "Epoch 10/30\n",
      "28709/28709 [==============================] - 17s 580us/sample - loss: 1.0859 - acc: 0.5841 - val_loss: 1.1971 - val_acc: 0.5454\n",
      "Epoch 11/30\n",
      "28709/28709 [==============================] - 17s 577us/sample - loss: 1.0608 - acc: 0.5970 - val_loss: 1.1710 - val_acc: 0.5521\n",
      "Epoch 12/30\n",
      "28709/28709 [==============================] - 17s 575us/sample - loss: 1.0408 - acc: 0.6049 - val_loss: 1.2017 - val_acc: 0.5343\n",
      "Epoch 13/30\n",
      "28709/28709 [==============================] - 17s 583us/sample - loss: 1.0152 - acc: 0.6142 - val_loss: 1.1814 - val_acc: 0.5531\n",
      "Epoch 14/30\n",
      "28709/28709 [==============================] - 16s 571us/sample - loss: 0.9943 - acc: 0.6203 - val_loss: 1.1629 - val_acc: 0.5580\n",
      "Epoch 15/30\n",
      "28709/28709 [==============================] - 17s 585us/sample - loss: 0.9759 - acc: 0.6289 - val_loss: 1.1824 - val_acc: 0.5603\n",
      "Epoch 16/30\n",
      "28709/28709 [==============================] - 17s 580us/sample - loss: 0.9503 - acc: 0.6372 - val_loss: 1.1787 - val_acc: 0.5628\n",
      "Epoch 17/30\n",
      "28709/28709 [==============================] - 17s 575us/sample - loss: 0.9350 - acc: 0.6457 - val_loss: 1.2225 - val_acc: 0.5479\n",
      "Epoch 18/30\n",
      "28709/28709 [==============================] - 17s 580us/sample - loss: 0.9148 - acc: 0.6528 - val_loss: 1.1884 - val_acc: 0.5500\n",
      "Epoch 19/30\n",
      "28709/28709 [==============================] - 17s 581us/sample - loss: 0.9041 - acc: 0.6574 - val_loss: 1.1613 - val_acc: 0.5660\n",
      "Epoch 20/30\n",
      "28709/28709 [==============================] - 17s 579us/sample - loss: 0.8974 - acc: 0.6602 - val_loss: 1.1892 - val_acc: 0.5634\n",
      "Epoch 21/30\n",
      "28709/28709 [==============================] - 16s 570us/sample - loss: 0.8697 - acc: 0.6731 - val_loss: 1.1836 - val_acc: 0.5752\n",
      "Epoch 22/30\n",
      "28709/28709 [==============================] - 16s 567us/sample - loss: 0.8683 - acc: 0.6709 - val_loss: 1.1779 - val_acc: 0.5665\n",
      "Epoch 23/30\n",
      "28709/28709 [==============================] - 16s 570us/sample - loss: 0.8471 - acc: 0.6811 - val_loss: 1.1929 - val_acc: 0.5691\n",
      "Epoch 24/30\n",
      "28709/28709 [==============================] - 16s 573us/sample - loss: 0.8318 - acc: 0.6864 - val_loss: 1.2228 - val_acc: 0.5592\n",
      "Epoch 25/30\n",
      "28709/28709 [==============================] - 17s 583us/sample - loss: 0.8167 - acc: 0.6914 - val_loss: 1.2344 - val_acc: 0.5538\n",
      "Epoch 26/30\n",
      "28709/28709 [==============================] - 16s 568us/sample - loss: 0.8154 - acc: 0.6928 - val_loss: 1.1870 - val_acc: 0.5761\n",
      "Epoch 27/30\n",
      "28709/28709 [==============================] - 16s 573us/sample - loss: 0.7914 - acc: 0.7023 - val_loss: 1.2080 - val_acc: 0.5736\n",
      "Epoch 28/30\n",
      "28709/28709 [==============================] - 17s 577us/sample - loss: 0.7868 - acc: 0.7018 - val_loss: 1.1893 - val_acc: 0.5727\n",
      "Epoch 29/30\n",
      "28709/28709 [==============================] - 17s 576us/sample - loss: 0.7767 - acc: 0.7080 - val_loss: 1.2104 - val_acc: 0.5719\n",
      "Epoch 30/30\n",
      "28709/28709 [==============================] - 17s 575us/sample - loss: 0.7615 - acc: 0.7137 - val_loss: 1.2565 - val_acc: 0.5711\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=X_train,\n",
    "                 y=y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have got top three validation scores of, 57.52%,57.27%, and 57.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
